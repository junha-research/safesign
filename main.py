import streamlit as st
import re
import os
import time
from dotenv import load_dotenv

# [Import] ê°™ì€ í´ë”ì— ìˆëŠ” toxic_detector.pyë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from src.toxic_detector import ToxicClauseDetector

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸° (Standard Ver.)",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ë”ë¯¸ ë°ì´í„° ë° íŒŒì‹± í•¨ìˆ˜ ---
def get_dummy_contract_text():
    """í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ê·¼ë¡œê³„ì•½ì„œ í…ìŠ¤íŠ¸"""
    return """
ì œ1ì¡° (ëª©ì )
ë³¸ ê³„ì•½ì€ ì‚¬ìš©ì (ì£¼)ì•…ë•ìƒì‚¬(ì´í•˜ "ê°‘")ì™€ ê·¼ë¡œì í™ê¸¸ë™(ì´í•˜ "ì„")ì˜ ê·¼ë¡œì¡°ê±´ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.

ì œ2ì¡° (ê·¼ë¡œì¥ì†Œ ë° ì—…ë¬´)
"ì„"ì€ "ê°‘"ì˜ ë³¸ì‚¬ ë° "ê°‘"ì´ ì§€ì •í•˜ëŠ” ì¥ì†Œì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤.

ì œ3ì¡° (ê·¼ë¡œì‹œê°„)
1. ê·¼ë¡œì‹œê°„ì€ 09:00ë¶€í„° 18:00ê¹Œì§€ë¡œ í•œë‹¤ (íœ´ê²Œì‹œê°„ 1ì‹œê°„ í¬í•¨).
2. "ê°‘"ì€ ì—…ë¬´ìƒ í•„ìš”í•œ ê²½ìš° "ì„"ì—ê²Œ ì—°ì¥, ì•¼ê°„ ë° íœ´ì¼ê·¼ë¡œë¥¼ ëª…í•  ìˆ˜ ìˆìœ¼ë©° "ì„"ì€ ì´ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.

ì œ4ì¡° (ì„ê¸ˆ)
1. ì›” ê¸‰ì—¬ëŠ” 2,500,000ì›ìœ¼ë¡œ í•œë‹¤.
2. ìœ„ ê¸‰ì—¬ì—ëŠ” ì‹ëŒ€, êµí†µë¹„ ë° ë²•ì • ì œìˆ˜ë‹¹(ì—°ì¥, ì•¼ê°„, íœ´ì¼ê·¼ë¡œìˆ˜ë‹¹ ë“±)ì´ ëª¨ë‘ í¬í•¨ëœ í¬ê´„ì„ê¸ˆìœ¼ë¡œ ì‚°ì •í•˜ë©°, "ì„"ì€ ì¶”ê°€ì ì¸ ìˆ˜ë‹¹ì„ ì²­êµ¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì œ5ì¡° (í‡´ì§ê¸ˆ)
"ì„"ì´ ì…ì‚¬ í›„ 1ë…„ ë¯¸ë§Œì— í‡´ì‚¬í•˜ëŠ” ê²½ìš°, ìˆ˜ìŠµê¸°ê°„ ë™ì•ˆì˜ êµìœ¡ë¹„ ë° ì†í•´ë°°ìƒ ëª…ëª©ìœ¼ë¡œ í‡´ì§ê¸ˆì€ ì§€ê¸‰í•˜ì§€ ì•„ë‹ˆí•œë‹¤.

ì œ6ì¡° (ê³„ì•½í•´ì§€)
"ì„"ì´ ë¬´ë‹¨ê²°ê·¼ 3ì¼ ì´ìƒ ì§€ì†í•˜ê±°ë‚˜ ì—…ë¬´ ëŠ¥ë ¥ì´ í˜„ì €íˆ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë  ê²½ìš° "ê°‘"ì€ ì¦‰ì‹œ ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆë‹¤.

ì œ7ì¡° (ì†í•´ë°°ìƒ)
"ì„"ì´ ê³„ì•½ê¸°ê°„ ì¤‘ í‡´ì‚¬í•˜ì—¬ "ê°‘"ì—ê²Œ ì†í•´ë¥¼ ì…íŒ ê²½ìš°, "ì„"ì€ "ê°‘"ì—ê²Œ ì¼ê¸ˆ 1,000ë§Œì›ì„ ë°°ìƒí•˜ì—¬ì•¼ í•œë‹¤.
"""

def parse_text_to_chunks(text):
    """í…ìŠ¤íŠ¸ë¥¼ 'ì œNì¡°' ê¸°ì¤€ìœ¼ë¡œ ìë¥´ëŠ” íŒŒì„œ"""
    split_pattern = r'(?=\n\s*ì œ\s*\d+\s*ì¡°)'
    chunks = re.split(split_pattern, text)
    # ê³µë°± ì œê±° ë° ìœ íš¨í•œ ì¡°í•­ë§Œ í•„í„°ë§
    clean_chunks = [c.strip() for c in chunks if len(c.strip()) > 10]
    return clean_chunks

# --- 3. ë‹¨ìœ„ ì‘ì—… í•¨ìˆ˜ (Helper) ---
def process_single_clause(detector, clause, index):
    """í•˜ë‚˜ì˜ ì¡°í•­ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # 1. ë…ì†Œì¡°í•­ íƒì§€
        detection = detector.detect(clause)
        
        # 2. ìˆ˜ì • ì œì•ˆ ìƒì„± (ë…ì†Œì¡°í•­ì¼ ë•Œë§Œ)
        suggestion = ""
        if detection['is_toxic']:
            suggestion = detector.generate_easy_suggestion(detection)
            
        return {
            "id": index + 1,
            "clause": clause,
            "is_toxic": detection['is_toxic'],
            "score": detection['risk_score'],
            "reason": detection['reason'],
            "context": detection['context_used'],
            "suggestion": suggestion,
            "status": "success"
        }
    except Exception as e:
        return {
            "id": index + 1,
            "clause": clause,
            "error": str(e),
            "status": "error"
        }

# --- 4. ë©”ì¸ ì–´í”Œë¦¬ì¼€ì´ì…˜ ---
def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("âš–ï¸ Contract Guardian")
        st.markdown("---")
        
        load_dotenv()
        env_key = os.getenv("GEMINI_API_KEY")
        
        api_key_input = st.text_input(
            "Gemini API Key", 
            value=env_key if env_key else "", 
            type="password"
        )
        if api_key_input:
            os.environ["GEMINI_API_KEY"] = api_key_input

        st.info("ğŸ’¡ ìˆœì°¨ ì²˜ë¦¬(Sequential Processing) ë°©ì‹ì˜ ì•ˆì •ì ì¸ ë°ëª¨ ë²„ì „ì…ë‹ˆë‹¤.")

    # ë©”ì¸ í™”ë©´
    st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ë…ì†Œì¡°í•­ íŒë³„ê¸°")
    st.markdown("ê³„ì•½ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ AIê°€ **í•œ ì¡°í•­ì”© ê¼¼ê¼¼í•˜ê²Œ** ë¶„ì„í•©ë‹ˆë‹¤.")

    # [ì…ë ¥ ì˜ì—­] í…ìŠ¤íŠ¸ ì—ë””í„° ì‚¬ìš©
    default_text = get_dummy_contract_text()
    contract_text = st.text_area("ê³„ì•½ì„œ ë‚´ìš© (ìˆ˜ì • ê°€ëŠ¥)", value=default_text, height=300)

    # API í‚¤ ì²´í¬
    if not os.environ.get("GEMINI_API_KEY"):
        st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    # [ë¶„ì„ ë²„íŠ¼]
    if st.button("ğŸš€ ë…ì†Œì¡°í•­ ë¶„ì„ ì‹œì‘", use_container_width=True):
        
        # 1. Parsing
        chunks = parse_text_to_chunks(contract_text)
        
        if not chunks:
            st.error("ë¶„ì„í•  ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ì œNì¡°' í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # 2. Detector ì´ˆê¸°í™” (ìºì‹±)
        @st.cache_resource
        def get_detector():
            # [ì¤‘ìš”] ê°ì²´ ìƒì„± ì‹œ ê´„í˜¸ () í•„ìˆ˜
            return ToxicClauseDetector()
        
        with st.spinner("âš™ï¸ ë²•ë ¹ DB ë° AI ì—”ì§„ ì´ˆê¸°í™” ì¤‘... (ìµœì´ˆ 1íšŒë§Œ ì†Œìš”)"):
            detector = get_detector()

        st.info(f"ì´ {len(chunks)}ê°œì˜ ì¡°í•­ì„ ìˆœì„œëŒ€ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

        # 3. ìˆœì°¨ ì‹¤í–‰ ë£¨í”„ (Sequential Loop)
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, clause in enumerate(chunks):
            # ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ
            status_text.markdown(f"**ğŸ•µï¸ ë¶„ì„ ì¤‘ ({i+1}/{len(chunks)}):** ì œ{i+1}ì¡° ì‹¬ì‚¬ ì¤‘...")
            
            # --- ë¶„ì„ ì‹¤í–‰ (ë™ê¸° ë°©ì‹) ---
            res = process_single_clause(detector, clause, i)
            results.append(res)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_bar.progress((i + 1) / len(chunks))
            
            # ì§§ì€ ëŒ€ê¸° (UXìš©, ë„ˆë¬´ ë¹ ë¥´ë©´ ëˆˆì— ì•ˆ ë³´ì¼ ìˆ˜ ìˆìŒ)
            # time.sleep(0.1) 

        status_text.success("âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.session_state.analysis_results = results # ê²°ê³¼ ì €ì¥
        
        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        st.divider()
        
        # ìš”ì•½ ì§€í‘œ
        toxic_count = sum(1 for r in results if r.get('is_toxic'))
        col1, col2 = st.columns(2)
        col1.metric("ë¶„ì„ëœ ì¡°í•­", f"{len(results)}ê±´")
        col2.metric("ë°œê²¬ëœ ìœ„í—˜ ì¡°í•­", f"{toxic_count}ê±´", delta="-ì£¼ì˜" if toxic_count > 0 else "ì•ˆì „")

        # ìƒì„¸ ê²°ê³¼ íƒ­
        tab1, tab2 = st.tabs(["ğŸš¨ ìœ„í—˜ ì¡°í•­ ë¦¬í¬íŠ¸", "ğŸ“‘ ì „ì²´ ì¡°í•­ ë³´ê¸°"])
        
        with tab1:
            if toxic_count == 0:
                st.success("ë…ì†Œì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                for res in results:
                    if res.get('is_toxic'):
                        with st.expander(f"âš ï¸ [ìœ„í—˜] ì œ{res['id']}ì¡° (ìœ„í—˜ë„: {res['score']})", expanded=True):
                            c1, c2 = st.columns(2)
                            with c1:
                                st.caption("ì›ë¬¸")
                                st.error(res['clause'])
                                st.markdown(f"**íŒë‹¨ ê·¼ê±°:** {res['reason']}")
                            with c2:
                                st.caption("AI ì†”ë£¨ì…˜")
                                st.markdown(res['suggestion'])
                                with st.popover("ì°¸ê³  ë²•ë ¹ í™•ì¸"):
                                    st.text(res['context'])
        
        with tab2:
            for res in results:
                icon = "ğŸ”´" if res.get('is_toxic') else "ğŸŸ¢"
                with st.expander(f"{icon} ì œ{res['id']}ì¡°"):
                    st.write(res['clause'])
                    if 'error' in res:
                        st.error(f"ì—ëŸ¬: {res['error']}")
                    else:
                        st.caption(f"íŒë‹¨ ê²°ê³¼: {res['reason']}")

if __name__ == "__main__":
    main()