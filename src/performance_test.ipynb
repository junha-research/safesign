{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf59f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py312_legai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import mimetypes\n",
    "\n",
    "# Gemini & LangChain & DeepEval\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_community.llms import Ollama\n",
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b25d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [í•µì‹¬] ìš°ë¦¬ê°€ ë§Œë“  ì„œë¹„ìŠ¤ ëª¨ë“ˆ (src í´ë”ê°€ ìˆì–´ì•¼ í•¨)\n",
    "# ë§Œì•½ src í´ë”ê°€ ì—†ë‹¤ë©´, ì´ ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬í•˜ê³  Mock Classë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    from toxic_detector import ToxicClauseDetector\n",
    "    from llm_service import LLM_gemini\n",
    "    from ollama_wrapper import OllamaDeepEvalWrapper\n",
    "    from law.legal_context import LawContextManager\n",
    "    from law.precedent_context import PrecedentContextManager\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ 'src' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71508faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. í™˜ê²½ ì„¤ì • ---\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "IMAGE_DIR = \"images/\"  # ê³„ì•½ì„œ ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” í´ë”\n",
    "DATASET_CSV = \"contract_dataset.csv\"\n",
    "RESULT_CSV = \"model_performance_results.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41394f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. [ìˆ˜ì •ë¨] Gemini Visionì„ ì´ìš©í•œ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ---\n",
    "def extract_text_with_gemini(image_path, api_key):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ íŒŒì¼(JPG, PNG ë“±)ì„ Geminiì—ê²Œ ë³´ì—¬ì£¼ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    (OCR ëŒ€ì²´)\n",
    "    \"\"\"\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    \n",
    "    # íŒŒì¼ MIME íƒ€ì… ê°ì§€\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    if not mime_type:\n",
    "        mime_type = \"image/png\" # ê¸°ë³¸ê°’\n",
    "\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ê·¼ë¡œê³„ì•½ì„œ ì¡°í•­ í…ìŠ¤íŠ¸ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì¶”ì¶œí•´ì¤˜.\n",
    "        ì¡°í•­ ì‚¬ì´ëŠ” ì¤„ë°”ê¿ˆ(Enter) ë‘ ë²ˆìœ¼ë¡œ êµ¬ë¶„í•´ì¤˜.\n",
    "        ì„¤ëª…ì´ë‚˜ ìš”ì•½ì€ í•˜ì§€ ë§ê³  í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•´.\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=[\n",
    "                types.Content(\n",
    "                    parts=[\n",
    "                        types.Part(text=prompt),\n",
    "                        types.Part(\n",
    "                            inline_data=types.Blob(\n",
    "                                mime_type=mime_type,\n",
    "                                data=image_bytes\n",
    "                            )\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        return response.text if response.text else \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Gemini Vision Error ({os.path.basename(image_path)}): {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7740d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_from_images(image_dir):\n",
    "    \"\"\"ì´ë¯¸ì§€ í´ë” -> í…ìŠ¤íŠ¸ ì¶”ì¶œ -> DataFrame ìƒì„±\"\"\"\n",
    "    print(f\"ğŸ“‚ '{image_dir}' í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìŠ¤ìº”í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ì§€ì›í•  ì´ë¯¸ì§€ í™•ì¥ì\n",
    "    exts = ['*.jpg', '*.jpeg', '*.png', '*.webp']\n",
    "    image_files = []\n",
    "    for ext in exts:\n",
    "        image_files.extend(glob.glob(os.path.join(image_dir, ext)))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame([\n",
    "            {\"file\": \"dummy.jpg\", \"clause_id\": 1, \"text\": \"ì œ3ì¡° (ì„ê¸ˆ) ì›” ê¸‰ì—¬ëŠ” 200ë§Œì›ìœ¼ë¡œ í•˜ë©° í¬ê´„ì„ê¸ˆìœ¼ë¡œ í•œë‹¤.\", \"label_toxic\": True},\n",
    "            {\"file\": \"dummy.jpg\", \"clause_id\": 2, \"text\": \"ì œ10ì¡° (ê·¼ë¡œì‹œê°„) 09:00~18:00 (íœ´ê²Œ 1ì‹œê°„)\", \"label_toxic\": False}\n",
    "        ])\n",
    "\n",
    "    print(f\"ğŸ” ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. Geminië¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘...\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        # Gemini Vision í˜¸ì¶œ\n",
    "        full_text = extract_text_with_gemini(img_path, GEMINI_API_KEY)\n",
    "        \n",
    "        # ì¡°í•­ë³„ ë¶„ë¦¬ (ê°„ë‹¨íˆ ì¤„ë°”ê¿ˆ 2ë²ˆ ê¸°ì¤€)\n",
    "        # ì‹¤ì œë¡œëŠ” 'ì œNì¡°' ì •ê·œì‹ìœ¼ë¡œ ìë¥´ëŠ” ê²Œ ë” ì •í™•í•¨\n",
    "        clauses = full_text.split(\"\\n\\n\")\n",
    "        \n",
    "        for i, clause in enumerate(clauses):\n",
    "            clean_text = clause.strip()\n",
    "            if len(clean_text) > 10: # ë…¸ì´ì¦ˆ ì œê±°\n",
    "                data.append({\n",
    "                    \"file\": os.path.basename(img_path),\n",
    "                    \"clause_id\": i + 1,\n",
    "                    \"text\": clean_text,\n",
    "                    \"label_toxic\": None # ì •ë‹µì€ CSV ì €ì¥ í›„ ìˆ˜ë™ ì…ë ¥ í•„ìš”\n",
    "                })\n",
    "                \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2703da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. ë¹„êµ ëª¨ë¸ ì •ì˜ ---\n",
    "\n",
    "# 1) Base Gemini (No DeepEval)\n",
    "class BaseGeminiModel:\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        prompt = f\"ë‹¤ìŒ ê·¼ë¡œê³„ì•½ ì¡°í•­ì´ ë…ì†Œì¡°í•­(ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬)ì¸ì§€ íŒë‹¨í•´. ë§ìœ¼ë©´ 'TOXIC', ì•„ë‹ˆë©´ 'SAFE'ë¡œ ì‹œì‘í•´.\\n\\n{text}\"\n",
    "        try:\n",
    "            res = self.client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\", contents=prompt\n",
    "            )\n",
    "            return res.text\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "\n",
    "# [Case 2] Gemini + RAG (DeepEval Style Prompt)\n",
    "class GeminiRAGModel:\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "        self.law_manager = LawContextManager()\n",
    "        self.law_manager.initialize_database()\n",
    "        self.precedent_manager = PrecedentContextManager()\n",
    "        self.precedent_manager.initialize_database()\n",
    "    \n",
    "    def retrieve_context(self, text):\n",
    "        \"\"\"RAG: ë²•ë ¹ê³¼ íŒë¡€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "        laws = self.law_manager.search_relevant_laws(text)\n",
    "        cases = self.precedent_manager.search_relevant_precedents(text, k=1)\n",
    "        \n",
    "        law_text = \"\\n\".join(laws) if laws else \"ê´€ë ¨ ë²•ë ¹ ì—†ìŒ\"\n",
    "        case_text = cases[0] if cases else \"ê´€ë ¨ íŒë¡€ ì—†ìŒ\"\n",
    "        \n",
    "        return f\"[ê´€ë ¨ ë²•ë ¹]\\n{law_text}\\n\\n[ê´€ë ¨ íŒë¡€]\\n{case_text}\"\n",
    "\n",
    "    def predict(self, text):\n",
    "        # RAG Context ê²€ìƒ‰\n",
    "        context = self.retrieve_context(text)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        [Context]\\n{context}\\n\n",
    "        [Input]\\n{text}\\n\n",
    "        ìœ„ ë²•ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì¡°í•­ì´ ë…ì†Œì¡°í•­ì¸ì§€ íŒë‹¨í•´. \n",
    "        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ 'TOXIC' ë˜ëŠ” 'SAFE'ë¡œ ì‹œì‘í•´ì•¼ í•´.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            res = self.client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\", contents=prompt\n",
    "            )\n",
    "            return res.text\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "\n",
    "# 3) Our Framework (SafeSign Logic)\n",
    "class OurFrameworkModel:\n",
    "    def __init__(self):\n",
    "        self.detector = ToxicClauseDetector() # toxic_detector\n",
    "    \n",
    "    def predict(self, text):\n",
    "        # RAG + G-Eval Rubric ì ìš©ëœ ì™„ì „ì²´\n",
    "        res = self.detector.detect(text)\n",
    "        status = \"TOXIC\" if res['is_toxic'] else \"SAFE\"\n",
    "        return f\"[{status}] Score:{res['risk_score']} / Reason:{res['reason']}\"\n",
    "\n",
    "# 4) Ollama Local (On-Device)\n",
    "class OllamaRAGModel:\n",
    "    def __init__(self, model_name=\"llama3\"):\n",
    "        # 1. Ollama ëª¨ë¸ ì¤€ë¹„\n",
    "        self.llm = OllamaDeepEvalWrapper(model_name=model_name)\n",
    "        \n",
    "        # 2. RAG ë„êµ¬ ì¤€ë¹„ (ë²•ë ¹, íŒë¡€ ê²€ìƒ‰ê¸°)\n",
    "        self.law_manager = LawContextManager()\n",
    "        self.law_manager.initialize_database()\n",
    "        \n",
    "        self.precedent_manager = PrecedentContextManager()\n",
    "        self.precedent_manager.initialize_database()\n",
    "\n",
    "        # 3. í‰ê°€ì(Judge) ì¤€ë¹„ - í‰ê°€ëŠ” ë˜‘ë˜‘í•œ Geminiê°€ ë‹´ë‹¹\n",
    "        self.evaluator_llm = LLM_gemini(model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "    def retrieve_context(self, text):\n",
    "        \"\"\"RAG: ë²•ë ¹ê³¼ íŒë¡€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "        laws = self.law_manager.search_relevant_laws(text)\n",
    "        cases = self.precedent_manager.search_relevant_precedents(text, k=1)\n",
    "        \n",
    "        law_text = \"\\n\".join(laws) if laws else \"ê´€ë ¨ ë²•ë ¹ ì—†ìŒ\"\n",
    "        case_text = cases[0] if cases else \"ê´€ë ¨ íŒë¡€ ì—†ìŒ\"\n",
    "        \n",
    "        return f\"[ê´€ë ¨ ë²•ë ¹]\\n{law_text}\\n\\n[ê´€ë ¨ íŒë¡€]\\n{case_text}\"\n",
    "\n",
    "    def predict_and_evaluate(self, text):\n",
    "        # Step 1: Retrieval (RAG)\n",
    "        context = self.retrieve_context(text)\n",
    "        \n",
    "        # Step 2: Generation (Ollama)\n",
    "        prompt = f\"\"\"\n",
    "        ë‹¹ì‹ ì€ í•œêµ­ ë…¸ë™ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ë²•ì  ê·¼ê±°]ë¥¼ ì°¸ê³ í•˜ì—¬ [ì¡°í•­]ì´ ë…ì†Œì¡°í•­ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.\n",
    "        \n",
    "        [ë²•ì  ê·¼ê±°]:\n",
    "        {context}\n",
    "        \n",
    "        [ì¡°í•­]:\n",
    "        {text}\n",
    "        \n",
    "        ê²°ê³¼ë¥¼ 'íŒë‹¨: [ì•ˆì „/ìœ„í—˜]', 'ì´ìœ : ...' í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ë‹µí•˜ì„¸ìš”.\n",
    "        \"\"\"\n",
    "        actual_output = self.llm.generate(prompt)\n",
    "        \n",
    "        # Step 3: Evaluation (DeepEval Faithfulness)\n",
    "        # \"Ollamaê°€ ê·¼ê±°(ë²•ë ¹/íŒë¡€)ë¥¼ ë¬´ì‹œí•˜ê³  í—›ì†Œë¦¬ë¥¼ í–ˆëŠ”ì§€\" Geminiê°€ ê°ì‹œí•©ë‹ˆë‹¤.\n",
    "        try:\n",
    "            metric = FaithfulnessMetric(\n",
    "                threshold=0.5, \n",
    "                model=self.evaluator_llm, # ì‹¬íŒì€ Gemini\n",
    "                include_reason=True\n",
    "            )\n",
    "            test_case = LLMTestCase(\n",
    "                input=text,\n",
    "                actual_output=actual_output,\n",
    "                retrieval_context=[context] # Ollamaê°€ ì°¸ê³ í–ˆì–´ì•¼ í•  ì •ë‹µì§€\n",
    "            )\n",
    "            metric.measure(test_case)\n",
    "            \n",
    "            eval_result = f\"Faithfulness: {metric.score} ({'Pass' if metric.is_successful() else 'Fail'})\"\n",
    "        except Exception as e:\n",
    "            eval_result = f\"Eval Error: {e}\"\n",
    "            \n",
    "        return f\"{actual_output}\\n\\n--- [DeepEval ê²€ì¦] ---\\n{eval_result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. ì‹¤í–‰ ë£¨í”„ ---\n",
    "def main():\n",
    "    print(\"ğŸš€ [Step 1] ë°ì´í„° êµ¬ì¶• (Gemini Vision OCR)\")\n",
    "    if os.path.exists(DATASET_CSV):\n",
    "        print(f\"   - ê¸°ì¡´ ë°ì´í„° íŒŒì¼({DATASET_CSV})ì„ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "        df = pd.read_csv(DATASET_CSV)\n",
    "    else:\n",
    "        df = build_dataset_from_images(IMAGE_DIR)\n",
    "        df.to_csv(DATASET_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"   - ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ & ì €ì¥ ({DATASET_CSV})\")\n",
    "\n",
    "    print(f\"\\nğŸš€ [Step 2] 4ê°€ì§€ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (ì´ {len(df)}ê°œ ì¡°í•­)\")\n",
    "    \n",
    "    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    models = {\n",
    "        \"Gemini_Base\": BaseGeminiModel(),\n",
    "        # \"Gemini_DeepEval\": DeepEvalGeminiModel(), # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ\n",
    "        \"SafeSign_Framework\": OurFrameworkModel(),\n",
    "        \"Ollama_Local\": OllamaRAGModel(model_name=\"LiquidAI/LFM2-8B-A1B-GGUF\") \n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        print(f\"\\nProcessing ID {idx+1}...\")\n",
    "        \n",
    "        row_result = row.to_dict()\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                output = model.predict(text)\n",
    "            except Exception as e:\n",
    "                output = f\"Error: {e}\"\n",
    "            end_time = time.time()\n",
    "            \n",
    "            row_result[f\"{name}_Output\"] = output\n",
    "            row_result[f\"{name}_Time\"] = round(end_time - start_time, 2)\n",
    "            \n",
    "        results.append(row_result)\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(RESULT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nâœ… í‰ê°€ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {RESULT_CSV}\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "    print(\"\\n[í‰ê·  ì†Œìš” ì‹œê°„ ë¹„êµ]\")\n",
    "    time_cols = [c for c in res_df.columns if \"_Time\" in c]\n",
    "    print(res_df[time_cols].mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_legai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
